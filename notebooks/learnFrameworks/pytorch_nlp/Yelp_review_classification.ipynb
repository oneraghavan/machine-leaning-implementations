{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn , optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"./data/yelp/reviews_with_splits_lite.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>terrible place to work for i just heard a stor...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>hours , minutes total time for an extremely s...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>my less than stellar review is for service . w...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>i m granting one star because there s no way t...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>the food here is mediocre at best . i went aft...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55995</td>\n",
       "      <td>positive</td>\n",
       "      <td>great food . wonderful , friendly service . i ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55996</td>\n",
       "      <td>positive</td>\n",
       "      <td>charlotte should be the new standard for moder...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55997</td>\n",
       "      <td>positive</td>\n",
       "      <td>get the encore sandwich ! ! make sure to get i...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55998</td>\n",
       "      <td>positive</td>\n",
       "      <td>i m a pretty big ice cream gelato fan . pretty...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55999</td>\n",
       "      <td>positive</td>\n",
       "      <td>where else can you find all the parts and piec...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating                                             review  split\n",
       "0      negative  terrible place to work for i just heard a stor...  train\n",
       "1      negative   hours , minutes total time for an extremely s...  train\n",
       "2      negative  my less than stellar review is for service . w...  train\n",
       "3      negative  i m granting one star because there s no way t...  train\n",
       "4      negative  the food here is mediocre at best . i went aft...  train\n",
       "...         ...                                                ...    ...\n",
       "55995  positive  great food . wonderful , friendly service . i ...   test\n",
       "55996  positive  charlotte should be the new standard for moder...   test\n",
       "55997  positive  get the encore sandwich ! ! make sure to get i...   test\n",
       "55998  positive  i m a pretty big ice cream gelato fan . pretty...   test\n",
       "55999  positive  where else can you find all the parts and piec...   test\n",
       "\n",
       "[56000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorizer(object):\n",
    "    def __init__(self,vocab):\n",
    "        \n",
    "        self.vocab = sorted(vocab)\n",
    "        \n",
    "        self.word_to_ix = {}\n",
    "        self.ix_to_word = {}\n",
    "        \n",
    "        for ix,word in enumerate(vocab):\n",
    "            self.word_to_ix[word] = ix\n",
    "            self.ix_to_word[ix] = word\n",
    "        \n",
    "    @classmethod\n",
    "    def create_vocab_and_vectorize_from_df(cls,reviews_df):\n",
    "        \n",
    "        word_count = {}\n",
    "        \n",
    "        all_words = [k for i in reviews_df.review.values for k in i.split(\" \")]\n",
    "        \n",
    "        for word in all_words:\n",
    "            if word in word_count.keys():\n",
    "                word_count[word] = word_count[word] + 1\n",
    "            else:\n",
    "                word_count[word] = 1\n",
    "        \n",
    "        vocab = []\n",
    "        \n",
    "        for word , word_count in word_count.items():\n",
    "            if(word_count > 25):\n",
    "                vocab.append(word)\n",
    "        return cls(vocab)\n",
    "    \n",
    "    def vectorize(self,review):\n",
    "        one_hot = np.zeros(len(self.vocab))\n",
    "        \n",
    "        for word in review.split(\" \"):\n",
    "            if word in self.vocab:\n",
    "                one_hot[self.word_to_ix[word]] = 1\n",
    "         \n",
    "        return one_hot\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = Vectorizer.create_vocab_and_vectorize_from_df(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(vect.vectorize(reviews.review.values[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self,review_df,vectorizer):\n",
    "        \n",
    "        self.df = review_df\n",
    "        self.vectorizer = vectorizer\n",
    "\n",
    "        self.train = review_df[review_df[\"split\"] == \"train\"]\n",
    "        self.test = review_df[review_df[\"split\"] == \"test\"]\n",
    "        self.valid = review_df[review_df[\"split\"] == \"valid\"]\n",
    "        \n",
    "        self.set_split('train')\n",
    "        \n",
    "    def set_split(self, split):\n",
    "        self.target_df = self.df[self.df[\"split\"] == split]\n",
    "        \n",
    "        self.target_size= len(self.target_df)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's features (x_data) and label (y_target)\n",
    "        \"\"\"\n",
    "        row = self.target_df.iloc[index]\n",
    "\n",
    "        review_vector = \\\n",
    "            self.vectorizer.vectorize(row.review)\n",
    "        \n",
    "        if row.rating == \"negative\":\n",
    "            rating_index = 0\n",
    "        else:\n",
    "            rating_index = 1\n",
    "        \n",
    "        return {'x_data': review_vector,\n",
    "                'y_target': rating_index}\n",
    "\n",
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_size,out_size):\n",
    "        \n",
    "        super(RatingClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=in_size, \n",
    "                             out_features=out_size)\n",
    "    \n",
    "    def forward(self,x_in):\n",
    "        \n",
    "        return self.fc1(x_in).squeeze()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ReviewDataset(reviews,vect)\n",
    "def compute_accuracy(y_pred, y_target):\n",
    "    y_target = y_target.cpu()\n",
    "    y_pred_indices = (torch.sigmoid(y_pred)>0.5).cpu().long()#.max(dim=1)[1]\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_generator = generate_batches(dataset, batch_size=64, \n",
    "                                           device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.4257361304526233 86.11621732026134\n",
      "1 0.27875973237982793 91.28880718954245\n",
      "2 0.23338933732190162 92.46578839869285\n"
     ]
    }
   ],
   "source": [
    "classifier = RatingClassifier(len(vect.vocab),1).to('cpu')\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                 mode='min', factor=0.5,\n",
    "                                                 patience=1)\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    \n",
    "    dataset.set_split('train')\n",
    "    batch_generator = generate_batches(dataset, batch_size=64, \n",
    "                                           device='cpu')\n",
    "    \n",
    "    running_acc = 0\n",
    "    running_loss = 0\n",
    "    classifier.train()\n",
    "    \n",
    "    \n",
    "    for batch_index,batch in enumerate(batch_generator):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = classifier(x_in=batch[\"x_data\"].float())\n",
    "        \n",
    "        loss = loss_fn(y_pred,batch[\"y_target\"].float())\n",
    "        loss_t = loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "        acc_t = compute_accuracy(y_pred, batch['y_target'])\n",
    "        running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "        \n",
    "    print(epoch,running_loss,running_acc)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset, \n",
    "                                   batch_size=32, \n",
    "                                   device='cpu')\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "classifier.eval()\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    # compute the output\n",
    "    y_pred = classifier(x_in=batch['x_data'].float())\n",
    "\n",
    "    # compute the loss\n",
    "    loss = loss_fn(y_pred, batch['y_target'].float())\n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "    # compute the accuracy\n",
    "    acc_t = compute_accuracy(y_pred, batch['y_target'])\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorchnlp",
   "language": "python",
   "name": "pytorchnlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
